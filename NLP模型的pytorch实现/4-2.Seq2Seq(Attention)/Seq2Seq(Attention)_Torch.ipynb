{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "colab_type": "code",
    "id": "g1lbXXSDgync",
    "outputId": "e1ff3a6e-a10e-4ed5-b337-16ebc63b3e60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:80: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000488\n",
      "Epoch: 0800 cost = 0.000162\n",
      "Epoch: 1200 cost = 0.000080\n",
      "Epoch: 1600 cost = 0.000048\n",
      "Epoch: 2000 cost = 0.000031\n",
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code by Tae Hwan Jung(Jeff Jung) @graykode\n",
    "# Reference : https://github.com/hunkim/PyTorchZeroToAll/blob/master/14_2_seq2seq_att.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list\n",
    "\n",
    "# Parameter\n",
    "n_hidden = 128\n",
    "\n",
    "def make_batch(sentences):\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return Variable(torch.Tensor(input_batch)), Variable(torch.Tensor(output_batch)), Variable(torch.LongTensor(target_batch))\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
    "\n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = Variable(torch.empty([n_step, 1, n_class]))\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)\n",
    "        attn_scores = Variable(torch.zeros(n_step))  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch(sentences)\n",
    "\n",
    "# hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "hidden = Variable(torch.zeros(1, 1, n_hidden))\n",
    "\n",
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "    loss = criterion(output, target_batch.squeeze(0))\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test\n",
    "test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
    "test_batch = Variable(torch.Tensor(test_batch))\n",
    "predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n",
    "\n",
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attn, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2Seq(Attention)-Torch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
