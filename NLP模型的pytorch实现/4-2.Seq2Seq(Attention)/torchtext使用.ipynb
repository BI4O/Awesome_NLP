{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext\n",
    "\n",
    "# 准备语料\n",
    "text = \"\"\"Nowadays, many parents choose to send their children to study abroad, because everyone believes that foreign education takes the lead in the world. We can't deny the fact that education in the developed countries has many advantages, especially the idea of sharing is caring. The education pays special attention to the return of society. They aim to cultivate the students to be nice and considerate. The schools expects students to make a contribution to the world with what they have learned at school. The idea of sharing is caring calls for students to be the ones who care about others and are willing to offer help when someone is in need. The aim of education is to let students improve their talents and then find their places in the world. At the same time, they can make the world better with their skills.\"\"\"\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nowadays,',\n",
       " 'many',\n",
       " 'parents',\n",
       " 'choose',\n",
       " 'to',\n",
       " 'send',\n",
       " 'their',\n",
       " 'children',\n",
       " 'to',\n",
       " 'study',\n",
       " 'abroad,',\n",
       " 'because',\n",
       " 'everyone',\n",
       " 'believes',\n",
       " 'that',\n",
       " 'foreign',\n",
       " 'education',\n",
       " 'takes',\n",
       " 'the',\n",
       " 'lead',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world.',\n",
       " 'We',\n",
       " \"can't\",\n",
       " 'deny',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'education',\n",
       " 'in',\n",
       " 'the',\n",
       " 'developed',\n",
       " 'countries',\n",
       " 'has',\n",
       " 'many',\n",
       " 'advantages,',\n",
       " 'especially',\n",
       " 'the',\n",
       " 'idea',\n",
       " 'of',\n",
       " 'sharing',\n",
       " 'is',\n",
       " 'caring.',\n",
       " 'The',\n",
       " 'education',\n",
       " 'pays',\n",
       " 'special',\n",
       " 'attention',\n",
       " 'to',\n",
       " 'the',\n",
       " 'return',\n",
       " 'of',\n",
       " 'society.',\n",
       " 'They',\n",
       " 'aim',\n",
       " 'to',\n",
       " 'cultivate',\n",
       " 'the',\n",
       " 'students',\n",
       " 'to',\n",
       " 'be',\n",
       " 'nice',\n",
       " 'and',\n",
       " 'considerate.',\n",
       " 'The',\n",
       " 'schools',\n",
       " 'expects',\n",
       " 'students',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'contribution',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'with',\n",
       " 'what',\n",
       " 'they',\n",
       " 'have',\n",
       " 'learned',\n",
       " 'at',\n",
       " 'school.',\n",
       " 'The',\n",
       " 'idea',\n",
       " 'of',\n",
       " 'sharing',\n",
       " 'is',\n",
       " 'caring',\n",
       " 'calls',\n",
       " 'for',\n",
       " 'students',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'who',\n",
       " 'care',\n",
       " 'about',\n",
       " 'others',\n",
       " 'and',\n",
       " 'are',\n",
       " 'willing',\n",
       " 'to',\n",
       " 'offer',\n",
       " 'help',\n",
       " 'when',\n",
       " 'someone',\n",
       " 'is',\n",
       " 'in',\n",
       " 'need.',\n",
       " 'The',\n",
       " 'aim',\n",
       " 'of',\n",
       " 'education',\n",
       " 'is',\n",
       " 'to',\n",
       " 'let',\n",
       " 'students',\n",
       " 'improve',\n",
       " 'their',\n",
       " 'talents',\n",
       " 'and',\n",
       " 'then',\n",
       " 'find',\n",
       " 'their',\n",
       " 'places',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world.',\n",
       " 'At',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time,',\n",
       " 'they',\n",
       " 'can',\n",
       " 'make',\n",
       " 'the',\n",
       " 'world',\n",
       " 'better',\n",
       " 'with',\n",
       " 'their',\n",
       " 'skills.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = text.split(' ')\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Requested tokenizer  , valid choices are a callable that takes a single string as input, \"revtok\" for the revtok reversible tokenizer, \"subword\" for the revtok caps-aware tokenizer, \"spacy\" for the SpaCy English tokenizer, or \"moses\" for the NLTK port of the Moses tokenization script.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-568e78a474b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                             \u001b[0mtokenize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                             \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                             fix_length=10)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torchtext\\data\\field.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sequential, use_vocab, init_token, eos_token, fix_length, dtype, preprocessing, postprocessing, lower, tokenize, include_lengths, batch_first, pad_token, unk_token, pad_first, truncate_first, stop_words, is_target)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostprocessing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minclude_lengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minclude_lengths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torchtext\\data\\utils.py\u001b[0m in \u001b[0;36mget_tokenizer\u001b[1;34m(tokenizer)\u001b[0m\n\u001b[0;32m     59\u001b[0m                      \u001b[1;34m\"\\\"spacy\\\" for the SpaCy English tokenizer, or \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                      \u001b[1;34m\"\\\"moses\\\" for the NLTK port of the Moses tokenization \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                      \"script.\".format(tokenizer))\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Requested tokenizer  , valid choices are a callable that takes a single string as input, \"revtok\" for the revtok reversible tokenizer, \"subword\" for the revtok caps-aware tokenizer, \"spacy\" for the SpaCy English tokenizer, or \"moses\" for the NLTK port of the Moses tokenization script."
     ]
    }
   ],
   "source": [
    "text\n",
    "\n",
    "TEXT = torchtext.data.Field(lower=True,\n",
    "                            tokenize=' ',\n",
    "                            batch_first=True,\n",
    "                            fix_length=10)\n",
    "\n",
    "TEXT.build_vocab(text1, max_size=10000, min_freq=5)\n",
    "TEXT.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict([(1,1),(2,2)])\n",
    "\n",
    "d[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
