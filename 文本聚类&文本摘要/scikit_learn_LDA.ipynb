{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                                  categories=categories,\n",
    "                                  shuffle=True,\n",
    "                                  random_state=42)\n",
    "\n",
    "print(type(twenty_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签1：alt.atheism\n",
      "标签2：comp.graphics\n",
      "标签3：sci.med\n",
      "标签4：soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "\"\"\"得到的对象是bunch,它具有一些性质\"\"\"\n",
    "for k,w in enumerate(twenty_train.target_names):\n",
    "    print(f'标签{k+1}：{w}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twenty_train.data的数据类型： <class 'list'>\n",
      "twenty_train.data的样本数： 2257\n"
     ]
    }
   ],
   "source": [
    "\"\"\"bunch.data是所有的文档组成的列表\"\"\"\n",
    "print('twenty_train.data的数据类型：',type(twenty_train.data))\n",
    "print('twenty_train.data的样本数：',len(twenty_train.data))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"从data中去取出一篇来看看\"\"\"\n",
    "raw_data = twenty_train.data\n",
    "raw_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From  sd  city ac uk Michael Collier Subject  Converting images to HP LaserJet III Nntp-Posting-Host  hampton Organization  The City University Lines  Does anyone know of a good way standard PC application PD utility to convert tif img tga files into LaserJet III format We would also like to do the same converting to HPGL HP plotter files Please email any response Is this the correct group Thanks in advance Michael -- Michael Collier Programmer The Computer Unit Email  M P Collier uk ac city The City University Tel  - x London Fax  - EC V HB '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"定义清除特殊字符的方法clean\"\"\"\n",
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    if type(text) == str:\n",
    "        text_droped = re.sub(\"[\\d+\\s+\\.\\!\\/_,$%^*()+\\\"\\'\\?]+|[+——！，。？、~@#￥%……&*（）:]+\",\n",
    "                             \" \",  # 用空格来代替\n",
    "                             text)\n",
    "    else:\n",
    "        text_droped = []\n",
    "        for i in text:\n",
    "            text_droped.append(clean(i))\n",
    "            \n",
    "    return text_droped\n",
    "\n",
    "clean(twenty_train.data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2257, 1000),\n",
       " ['ability',\n",
       "  'able',\n",
       "  'absolute',\n",
       "  'absolutes',\n",
       "  'ac',\n",
       "  'accept',\n",
       "  'accepted',\n",
       "  'access',\n",
       "  'according',\n",
       "  'account',\n",
       "  'act',\n",
       "  'action',\n",
       "  'actions',\n",
       "  'acts',\n",
       "  'actually',\n",
       "  'ad',\n",
       "  'add',\n",
       "  'address',\n",
       "  'admit',\n",
       "  'advance',\n",
       "  'advice',\n",
       "  'age',\n",
       "  'ago',\n",
       "  'agree',\n",
       "  'ai',\n",
       "  'aids',\n",
       "  'algorithm',\n",
       "  'allan',\n",
       "  'allow',\n",
       "  'alt',\n",
       "  'alternative',\n",
       "  'american',\n",
       "  'amiga',\n",
       "  'analysis',\n",
       "  'ancient',\n",
       "  'andrew',\n",
       "  'animals',\n",
       "  'animation',\n",
       "  'answer',\n",
       "  'answers',\n",
       "  'anti',\n",
       "  'anybody',\n",
       "  'apparently',\n",
       "  'appears',\n",
       "  'apple',\n",
       "  'apply',\n",
       "  'appreciate',\n",
       "  'appreciated',\n",
       "  'approach',\n",
       "  'appropriate',\n",
       "  'apr',\n",
       "  'april',\n",
       "  'archive',\n",
       "  'area',\n",
       "  'aren',\n",
       "  'argue',\n",
       "  'argument',\n",
       "  'arguments',\n",
       "  'arrogance',\n",
       "  'art',\n",
       "  'article',\n",
       "  'articles',\n",
       "  'ask',\n",
       "  'asked',\n",
       "  'assume',\n",
       "  'assumption',\n",
       "  'atheism',\n",
       "  'atheist',\n",
       "  'atheists',\n",
       "  'athens',\n",
       "  'athos',\n",
       "  'au',\n",
       "  'austin',\n",
       "  'australia',\n",
       "  'author',\n",
       "  'authority',\n",
       "  'available',\n",
       "  'avoid',\n",
       "  'away',\n",
       "  'bad',\n",
       "  'banks',\n",
       "  'based',\n",
       "  'basic',\n",
       "  'basically',\n",
       "  'basis',\n",
       "  'beginning',\n",
       "  'behavior',\n",
       "  'belief',\n",
       "  'beliefs',\n",
       "  'believe',\n",
       "  'believed',\n",
       "  'believing',\n",
       "  'benedikt',\n",
       "  'berkeley',\n",
       "  'best',\n",
       "  'better',\n",
       "  'bible',\n",
       "  'biblical',\n",
       "  'big',\n",
       "  'bit',\n",
       "  'bitnet',\n",
       "  'black',\n",
       "  'blood',\n",
       "  'bob',\n",
       "  'bobby',\n",
       "  'body',\n",
       "  'book',\n",
       "  'books',\n",
       "  'born',\n",
       "  'box',\n",
       "  'brain',\n",
       "  'brian',\n",
       "  'bu',\n",
       "  'business',\n",
       "  'ca',\n",
       "  'cadre',\n",
       "  'california',\n",
       "  'called',\n",
       "  'caltech',\n",
       "  'came',\n",
       "  'canada',\n",
       "  'cancer',\n",
       "  'candida',\n",
       "  'card',\n",
       "  'care',\n",
       "  'carleton',\n",
       "  'case',\n",
       "  'cases',\n",
       "  'catholic',\n",
       "  'cause',\n",
       "  'caused',\n",
       "  'causes',\n",
       "  'cc',\n",
       "  'cco',\n",
       "  'center',\n",
       "  'century',\n",
       "  'certain',\n",
       "  'certainly',\n",
       "  'ch',\n",
       "  'change',\n",
       "  'changes',\n",
       "  'chastity',\n",
       "  'check',\n",
       "  'child',\n",
       "  'children',\n",
       "  'chinese',\n",
       "  'choice',\n",
       "  'choose',\n",
       "  'chris',\n",
       "  'christ',\n",
       "  'christian',\n",
       "  'christianity',\n",
       "  'christians',\n",
       "  'church',\n",
       "  'churches',\n",
       "  'city',\n",
       "  'claim',\n",
       "  'claims',\n",
       "  'clear',\n",
       "  'clearly',\n",
       "  'clh',\n",
       "  'clinical',\n",
       "  'close',\n",
       "  'cmu',\n",
       "  'code',\n",
       "  'college',\n",
       "  'color',\n",
       "  'colorado',\n",
       "  'colors',\n",
       "  'com',\n",
       "  'come',\n",
       "  'comes',\n",
       "  'coming',\n",
       "  'comments',\n",
       "  'common',\n",
       "  'community',\n",
       "  'comp',\n",
       "  'company',\n",
       "  'complete',\n",
       "  'completely',\n",
       "  'computer',\n",
       "  'computing',\n",
       "  'concept',\n",
       "  'concerned',\n",
       "  'conclusion',\n",
       "  'consider',\n",
       "  'considered',\n",
       "  'contact',\n",
       "  'contains',\n",
       "  'context',\n",
       "  'control',\n",
       "  'convert',\n",
       "  'copy',\n",
       "  'correct',\n",
       "  'cost',\n",
       "  'couldn',\n",
       "  'couple',\n",
       "  'course',\n",
       "  'covington',\n",
       "  'create',\n",
       "  'created',\n",
       "  'cross',\n",
       "  'cs',\n",
       "  'culture',\n",
       "  'current',\n",
       "  'currently',\n",
       "  'cut',\n",
       "  'cview',\n",
       "  'cwru',\n",
       "  'dan',\n",
       "  'data',\n",
       "  'date',\n",
       "  'dave',\n",
       "  'david',\n",
       "  'day',\n",
       "  'days',\n",
       "  'dead',\n",
       "  'deal',\n",
       "  'death',\n",
       "  'dec',\n",
       "  'decide',\n",
       "  'decided',\n",
       "  'define',\n",
       "  'defined',\n",
       "  'definition',\n",
       "  'deleted',\n",
       "  'department',\n",
       "  'dept',\n",
       "  'described',\n",
       "  'description',\n",
       "  'determine',\n",
       "  'developed',\n",
       "  'development',\n",
       "  'did',\n",
       "  'didn',\n",
       "  'die',\n",
       "  'died',\n",
       "  'diet',\n",
       "  'difference',\n",
       "  'differences',\n",
       "  'different',\n",
       "  'difficult',\n",
       "  'direct',\n",
       "  'directly',\n",
       "  'directory',\n",
       "  'disclaimer',\n",
       "  'discuss',\n",
       "  'discussion',\n",
       "  'disease',\n",
       "  'diseases',\n",
       "  'display',\n",
       "  'distribution',\n",
       "  'divine',\n",
       "  'division',\n",
       "  'doctor',\n",
       "  'doctors',\n",
       "  'doctrine',\n",
       "  'does',\n",
       "  'doesn',\n",
       "  'doing',\n",
       "  'don',\n",
       "  'dos',\n",
       "  'double',\n",
       "  'doubt',\n",
       "  'dr',\n",
       "  'drug',\n",
       "  'drugs',\n",
       "  'dsl',\n",
       "  'dyer',\n",
       "  'earlier',\n",
       "  'early',\n",
       "  'earth',\n",
       "  'east',\n",
       "  'easter',\n",
       "  'easy',\n",
       "  'eat',\n",
       "  'ed',\n",
       "  'education',\n",
       "  'effect',\n",
       "  'effective',\n",
       "  'effects',\n",
       "  'email',\n",
       "  'end',\n",
       "  'eng',\n",
       "  'engineering',\n",
       "  'entirely',\n",
       "  'environment',\n",
       "  'error',\n",
       "  'especially',\n",
       "  'et',\n",
       "  'eternal',\n",
       "  'event',\n",
       "  'events',\n",
       "  'evidence',\n",
       "  'evil',\n",
       "  'exactly',\n",
       "  'example',\n",
       "  'exist',\n",
       "  'existence',\n",
       "  'exists',\n",
       "  'expect',\n",
       "  'experience',\n",
       "  'explain',\n",
       "  'eye',\n",
       "  'eyes',\n",
       "  'face',\n",
       "  'fact',\n",
       "  'fairly',\n",
       "  'faith',\n",
       "  'fall',\n",
       "  'fallacy',\n",
       "  'false',\n",
       "  'family',\n",
       "  'faq',\n",
       "  'far',\n",
       "  'fast',\n",
       "  'father',\n",
       "  'fax',\n",
       "  'feel',\n",
       "  'fi',\n",
       "  'file',\n",
       "  'files',\n",
       "  'finally',\n",
       "  'fine',\n",
       "  'fit',\n",
       "  'follow',\n",
       "  'following',\n",
       "  'food',\n",
       "  'foods',\n",
       "  'form',\n",
       "  'format',\n",
       "  'formats',\n",
       "  'frank',\n",
       "  'fred',\n",
       "  'free',\n",
       "  'friend',\n",
       "  'ftp',\n",
       "  'function',\n",
       "  'future',\n",
       "  'gave',\n",
       "  'geb',\n",
       "  'general',\n",
       "  'generally',\n",
       "  'geneva',\n",
       "  'georgia',\n",
       "  'germany',\n",
       "  'gets',\n",
       "  'getting',\n",
       "  'gif',\n",
       "  'given',\n",
       "  'gives',\n",
       "  'gmt',\n",
       "  'god',\n",
       "  'gods',\n",
       "  'goes',\n",
       "  'going',\n",
       "  'good',\n",
       "  'gordon',\n",
       "  'gospel',\n",
       "  'got',\n",
       "  'gov',\n",
       "  'grace',\n",
       "  'graphics',\n",
       "  'great',\n",
       "  'greatly',\n",
       "  'gregg',\n",
       "  'group',\n",
       "  'groups',\n",
       "  'guess',\n",
       "  'hand',\n",
       "  'happen',\n",
       "  'happened',\n",
       "  'happy',\n",
       "  'hard',\n",
       "  'hardware',\n",
       "  'harvard',\n",
       "  'haven',\n",
       "  'having',\n",
       "  'head',\n",
       "  'health',\n",
       "  'hear',\n",
       "  'heard',\n",
       "  'heart',\n",
       "  'heaven',\n",
       "  'hell',\n",
       "  'help',\n",
       "  'hi',\n",
       "  'high',\n",
       "  'higher',\n",
       "  'highly',\n",
       "  'history',\n",
       "  'hiv',\n",
       "  'hold',\n",
       "  'holy',\n",
       "  'home',\n",
       "  'hope',\n",
       "  'host',\n",
       "  'hp',\n",
       "  'human',\n",
       "  'humans',\n",
       "  'ibm',\n",
       "  'ico',\n",
       "  'idea',\n",
       "  'ideas',\n",
       "  'ii',\n",
       "  'illinois',\n",
       "  'image',\n",
       "  'images',\n",
       "  'imagine',\n",
       "  'important',\n",
       "  'include',\n",
       "  'included',\n",
       "  'includes',\n",
       "  'including',\n",
       "  'info',\n",
       "  'information',\n",
       "  'innocent',\n",
       "  'instead',\n",
       "  'institute',\n",
       "  'intellect',\n",
       "  'intended',\n",
       "  'interested',\n",
       "  'interesting',\n",
       "  'internet',\n",
       "  'interpretation',\n",
       "  'involved',\n",
       "  'islam',\n",
       "  'islamic',\n",
       "  'isn',\n",
       "  'issue',\n",
       "  'issues',\n",
       "  'jaeger',\n",
       "  'james',\n",
       "  'jayne',\n",
       "  'jesus',\n",
       "  'jewish',\n",
       "  'jews',\n",
       "  'jim',\n",
       "  'john',\n",
       "  'jon',\n",
       "  'joseph',\n",
       "  'jpeg',\n",
       "  'judge',\n",
       "  'just',\n",
       "  'jxp',\n",
       "  'keith',\n",
       "  'ken',\n",
       "  'keywords',\n",
       "  'kill',\n",
       "  'kind',\n",
       "  'king',\n",
       "  'kingdom',\n",
       "  'kmr',\n",
       "  'knew',\n",
       "  'know',\n",
       "  'knowing',\n",
       "  'knowledge',\n",
       "  'known',\n",
       "  'knows',\n",
       "  'lab',\n",
       "  'lack',\n",
       "  'language',\n",
       "  'large',\n",
       "  'later',\n",
       "  'law',\n",
       "  'laws',\n",
       "  'learn',\n",
       "  'leave',\n",
       "  'left',\n",
       "  'legal',\n",
       "  'let',\n",
       "  'level',\n",
       "  'levels',\n",
       "  'lewis',\n",
       "  'library',\n",
       "  'lie',\n",
       "  'life',\n",
       "  'light',\n",
       "  'like',\n",
       "  'likely',\n",
       "  'line',\n",
       "  'list',\n",
       "  'little',\n",
       "  'live',\n",
       "  'lives',\n",
       "  'livesey',\n",
       "  'living',\n",
       "  'll',\n",
       "  'local',\n",
       "  'logic',\n",
       "  'logical',\n",
       "  'long',\n",
       "  'longer',\n",
       "  'look',\n",
       "  'looked',\n",
       "  'looking',\n",
       "  'looks',\n",
       "  'lord',\n",
       "  'lost',\n",
       "  'lot',\n",
       "  'lots',\n",
       "  'love',\n",
       "  'low',\n",
       "  'luke',\n",
       "  'ma',\n",
       "  'mac',\n",
       "  'machine',\n",
       "  'mail',\n",
       "  'major',\n",
       "  'make',\n",
       "  'makes',\n",
       "  'making',\n",
       "  'man',\n",
       "  'mantis',\n",
       "  'mark',\n",
       "  'marriage',\n",
       "  'married',\n",
       "  'mary',\n",
       "  'mass',\n",
       "  'material',\n",
       "  'mathew',\n",
       "  'matter',\n",
       "  'matthew',\n",
       "  'maybe',\n",
       "  'md',\n",
       "  'mean',\n",
       "  'meaning',\n",
       "  'means',\n",
       "  'med',\n",
       "  'media',\n",
       "  'medical',\n",
       "  'medicine',\n",
       "  'member',\n",
       "  'memory',\n",
       "  'men',\n",
       "  'mention',\n",
       "  'mentioned',\n",
       "  'merely',\n",
       "  'message',\n",
       "  'messiah',\n",
       "  'method',\n",
       "  'methodology',\n",
       "  'michael',\n",
       "  'mike',\n",
       "  'mil',\n",
       "  'mind',\n",
       "  'mit',\n",
       "  'mode',\n",
       "  'model',\n",
       "  'modern',\n",
       "  'moment',\n",
       "  'monash',\n",
       "  'money',\n",
       "  'months',\n",
       "  'moral',\n",
       "  'morality',\n",
       "  'mot',\n",
       "  'mother',\n",
       "  'motto',\n",
       "  'mr',\n",
       "  'ms',\n",
       "  'msg',\n",
       "  'murder',\n",
       "  'muslim',\n",
       "  'muslims',\n",
       "  'nasa',\n",
       "  'national',\n",
       "  'natural',\n",
       "  'nature',\n",
       "  'navy',\n",
       "  'necessarily',\n",
       "  'necessary',\n",
       "  'need',\n",
       "  'needed',\n",
       "  'needs',\n",
       "  'net',\n",
       "  'netcom',\n",
       "  'network',\n",
       "  'new',\n",
       "  'news',\n",
       "  'newsgroup',\n",
       "  'newsletter',\n",
       "  'newsreader',\n",
       "  'nice',\n",
       "  'nl',\n",
       "  'nntp',\n",
       "  'non',\n",
       "  'noring',\n",
       "  'normal',\n",
       "  'north',\n",
       "  'note',\n",
       "  'number',\n",
       "  'object',\n",
       "  'objective',\n",
       "  'objects',\n",
       "  'obvious',\n",
       "  'obviously',\n",
       "  'office',\n",
       "  'oh',\n",
       "  'ohio',\n",
       "  'ok',\n",
       "  'okcforum',\n",
       "  'old',\n",
       "  'ones',\n",
       "  'open',\n",
       "  'opinion',\n",
       "  'opinions',\n",
       "  'order',\n",
       "  'org',\n",
       "  'original',\n",
       "  'outside',\n",
       "  'pa',\n",
       "  'package',\n",
       "  'page',\n",
       "  'pain',\n",
       "  'paper',\n",
       "  'particular',\n",
       "  'particularly',\n",
       "  'parts',\n",
       "  'pasadena',\n",
       "  'past',\n",
       "  'patient',\n",
       "  'patients',\n",
       "  'paul',\n",
       "  'pc',\n",
       "  'peace',\n",
       "  'people',\n",
       "  'perfect',\n",
       "  'person',\n",
       "  'personal',\n",
       "  'personally',\n",
       "  'peter',\n",
       "  'phone',\n",
       "  'physical',\n",
       "  'physics',\n",
       "  'picture',\n",
       "  'pictures',\n",
       "  'pitt',\n",
       "  'pittsburgh',\n",
       "  'pl',\n",
       "  'place',\n",
       "  'places',\n",
       "  'pm',\n",
       "  'po',\n",
       "  'point',\n",
       "  'points',\n",
       "  'political',\n",
       "  'polygon',\n",
       "  'poor',\n",
       "  'pope',\n",
       "  'portal',\n",
       "  'position',\n",
       "  'positive',\n",
       "  'possible',\n",
       "  'possibly',\n",
       "  'post',\n",
       "  'posted',\n",
       "  'poster',\n",
       "  'posting',\n",
       "  'postings',\n",
       "  'posts',\n",
       "  'postscript',\n",
       "  'power',\n",
       "  'practice',\n",
       "  'pray',\n",
       "  'prayer',\n",
       "  'present',\n",
       "  'pretty',\n",
       "  'prevent',\n",
       "  'previous',\n",
       "  'price',\n",
       "  'probably',\n",
       "  'problem',\n",
       "  'problems',\n",
       "  'process',\n",
       "  'processing',\n",
       "  'product',\n",
       "  'products',\n",
       "  'program',\n",
       "  'programming',\n",
       "  'programs',\n",
       "  'project',\n",
       "  'proof',\n",
       "  'prophecy',\n",
       "  'prophet',\n",
       "  'prove',\n",
       "  'provide',\n",
       "  'pub',\n",
       "  'public',\n",
       "  'punishment',\n",
       "  'purdue',\n",
       "  'purpose',\n",
       "  'quality',\n",
       "  'question',\n",
       "  'questions',\n",
       "  'quicktime',\n",
       "  'quite',\n",
       "  'quote',\n",
       "  'rate',\n",
       "  'ray',\n",
       "  'reaction',\n",
       "  'read',\n",
       "  'reading',\n",
       "  'real',\n",
       "  'reality',\n",
       "  'realize',\n",
       "  'really',\n",
       "  'reason',\n",
       "  'reasonable',\n",
       "  'reasoning',\n",
       "  'reasons',\n",
       "  'recent',\n",
       "  'recently',\n",
       "  'reference',\n",
       "  'regarding',\n",
       "  'related',\n",
       "  'relationship',\n",
       "  'religion',\n",
       "  'religions',\n",
       "  'religious',\n",
       "  'remember',\n",
       "  'reply',\n",
       "  'reported',\n",
       "  'require',\n",
       "  'required',\n",
       "  'requires',\n",
       "  'research',\n",
       "  'respect',\n",
       "  'response',\n",
       "  'rest',\n",
       "  'result',\n",
       "  'results',\n",
       "  'resurrection',\n",
       "  'revelation',\n",
       "  'rice',\n",
       "  'richard',\n",
       "  'right',\n",
       "  'risk',\n",
       "  'robert',\n",
       "  'rochester',\n",
       "  'romans',\n",
       "  'ron',\n",
       "  'rule',\n",
       "  'rules',\n",
       "  'run',\n",
       "  'running',\n",
       "  'rushdie',\n",
       "  'rutgers',\n",
       "  'sabbath',\n",
       "  'said',\n",
       "  'san',\n",
       "  'sandvik',\n",
       "  'sas',\n",
       "  'satan',\n",
       "  'saturn',\n",
       "  'save',\n",
       "  'saved',\n",
       "  'saw',\n",
       "  'say',\n",
       "  'saying',\n",
       "  'says',\n",
       "  'schneider',\n",
       "  'school',\n",
       "  'sci',\n",
       "  'science',\n",
       "  'scientific',\n",
       "  'scientists',\n",
       "  'scott',\n",
       "  'screen',\n",
       "  'scripture',\n",
       "  'sea',\n",
       "  'second',\n",
       "  'section',\n",
       "  'seeing',\n",
       "  'seen',\n",
       "  'self',\n",
       "  'send',\n",
       "  'sense',\n",
       "  'sensitivity',\n",
       "  'server',\n",
       "  'service',\n",
       "  'services',\n",
       "  'set',\n",
       "  'sex',\n",
       "  'sgi',\n",
       "  'shall',\n",
       "  'shameful',\n",
       "  'share',\n",
       "  'short',\n",
       "  'shouldn',\n",
       "  'significant',\n",
       "  'similar',\n",
       "  'simple',\n",
       "  'simply',\n",
       "  'sin',\n",
       "  'single',\n",
       "  'sins',\n",
       "  'site',\n",
       "  'sites',\n",
       "  'situation',\n",
       "  'size',\n",
       "  'skepticism',\n",
       "  'skin',\n",
       "  'small',\n",
       "  'social',\n",
       "  'society',\n",
       "  'software',\n",
       "  'solntze',\n",
       "  'son',\n",
       "  'soon',\n",
       "  'sorry',\n",
       "  'sort',\n",
       "  'soul',\n",
       "  'sound',\n",
       "  'sounds',\n",
       "  'source',\n",
       "  'sources',\n",
       "  'space',\n",
       "  'spdcc',\n",
       "  'speak',\n",
       "  'speaking',\n",
       "  'special',\n",
       "  'species',\n",
       "  'specific',\n",
       "  'specifically',\n",
       "  'sphere',\n",
       "  'spirit',\n",
       "  'spiritual',\n",
       "  'st',\n",
       "  'standard',\n",
       "  'stanford',\n",
       "  'start',\n",
       "  'started',\n",
       "  'state',\n",
       "  'statement',\n",
       "  'statements',\n",
       "  'states',\n",
       "  'stay',\n",
       "  'steve',\n",
       "  'stop',\n",
       "  'story',\n",
       "  'strong',\n",
       "  'student',\n",
       "  'studies',\n",
       "  'study',\n",
       "  'stuff',\n",
       "  'suggest',\n",
       "  'summary',\n",
       "  'sun',\n",
       "  'sunday',\n",
       "  'superstition',\n",
       "  'support',\n",
       "  'supports',\n",
       "  'suppose',\n",
       "  'supposed',\n",
       "  'sure',\n",
       "  'surely',\n",
       "  'surface',\n",
       "  'surrender',\n",
       "  'suspect',\n",
       "  'symptoms',\n",
       "  'syndrome',\n",
       "  'systems',\n",
       "  'taken',\n",
       "  'takes',\n",
       "  'taking',\n",
       "  'talk',\n",
       "  'talking',\n",
       "  'tar',\n",
       "  'teachings',\n",
       "  'technical',\n",
       "  'technology',\n",
       "  'tek',\n",
       "  'tell',\n",
       "  'tells',\n",
       "  'tend',\n",
       "  'term',\n",
       "  'terms',\n",
       "  'test',\n",
       "  'testament',\n",
       "  'text',\n",
       "  'th',\n",
       "  'thank',\n",
       "  'thanks',\n",
       "  'theology',\n",
       "  'theory',\n",
       "  'thing',\n",
       "  'things',\n",
       "  'think',\n",
       "  'thinking',\n",
       "  'thought',\n",
       "  'thoughts',\n",
       "  'tiff',\n",
       "  'time',\n",
       "  'times',\n",
       "  'tin',\n",
       "  'today',\n",
       "  'told',\n",
       "  'took',\n",
       "  'tool',\n",
       "  'tools',\n",
       "  'tradition',\n",
       "  'treatment',\n",
       "  'tried',\n",
       "  'trouble',\n",
       "  'true',\n",
       "  'truth',\n",
       "  'try',\n",
       "  'trying',\n",
       "  'tu',\n",
       "  'turn',\n",
       "  'type',\n",
       "  'uchicago',\n",
       "  'uga',\n",
       "  'uiuc',\n",
       "  'uk',\n",
       "  'umd',\n",
       "  'umich',\n",
       "  'understand',\n",
       "  'understanding',\n",
       "  'unfortunately',\n",
       "  'united',\n",
       "  'univ',\n",
       "  'universe',\n",
       "  'university',\n",
       "  'unix',\n",
       "  'unless',\n",
       "  'usa',\n",
       "  'use',\n",
       "  'used',\n",
       "  'useful',\n",
       "  'usenet',\n",
       "  'user',\n",
       "  'users',\n",
       "  'uses',\n",
       "  'using',\n",
       "  'usually',\n",
       "  'utexas',\n",
       "  'uucp',\n",
       "  'valid',\n",
       "  'value',\n",
       "  'values',\n",
       "  'various',\n",
       "  've',\n",
       "  'verse',\n",
       "  'version',\n",
       "  'vesa',\n",
       "  'vga',\n",
       "  'vice',\n",
       "  'video',\n",
       "  'view',\n",
       "  'views',\n",
       "  'virtual',\n",
       "  'vms',\n",
       "  'volume',\n",
       "  'want',\n",
       "  'wanted',\n",
       "  'wants',\n",
       "  'war',\n",
       "  'washington',\n",
       "  'wasn',\n",
       "  'water',\n",
       "  'way',\n",
       "  'ways',\n",
       "  'weak',\n",
       "  'week',\n",
       "  'weeks',\n",
       "  'weight',\n",
       "  'went',\n",
       "  'west',\n",
       "  'western',\n",
       "  'white',\n",
       "  'wife',\n",
       "  'willing',\n",
       "  'windows',\n",
       "  'wish',\n",
       "  'woman',\n",
       "  'women',\n",
       "  'won',\n",
       "  'word',\n",
       "  'words',\n",
       "  'work',\n",
       "  'working',\n",
       "  'works',\n",
       "  'world',\n",
       "  'worse',\n",
       "  'worship',\n",
       "  'wouldn',\n",
       "  'wpd',\n",
       "  'write',\n",
       "  'writing',\n",
       "  'written',\n",
       "  'wrong',\n",
       "  'wrote',\n",
       "  'year',\n",
       "  'years',\n",
       "  'yeast',\n",
       "  'yes',\n",
       "  'york',\n",
       "  'young'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"使用tf-idf对2257篇文档进行文本向量化\"\"\"\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# 只取1000个出现次数最多的词作为特征\n",
    "n_features = 1000\n",
    "tf_vectorizer = CountVectorizer(strip_accents='unicode',\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english',\n",
    "                                max_df=0.5,\n",
    "                                min_df=10)\n",
    "tf = tf_vectorizer.fit_transform(clean(twenty_train.data))\n",
    "tf.shape,tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50,\n",
       "             max_doc_update_iter=100, max_iter=100, mean_change_tol=0.001,\n",
       "             n_components=5, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"创建LDA模型，拟合数据\"\"\"\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_topics = 5\n",
    "lda = LatentDirichletAllocation(n_components=n_topics,\n",
    "                                max_iter=100,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50,\n",
    "                                random_state=0)\n",
    "# 开始查找主题\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"定义模型输出结果函数\"\"\"\n",
    "def print_top_words(model, feature_name, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        for i in topic.argsort()[:-n_top_words - 1:-1]:\n",
    "            print(feature_name[i],end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "com article msg people medical health use food like know \n",
      "Topic #1:\n",
      "graphics image com university posting file software host mail nntp \n",
      "Topic #2:\n",
      "god jesus people believe does bible christians christian know think \n",
      "Topic #3:\n",
      "com keith pitt article cs gordon banks caltech geb sgi \n",
      "Topic #4:\n",
      "think people article don science just com like university uk "
     ]
    }
   ],
   "source": [
    "\"\"\"输出结果\"\"\"\n",
    "\n",
    "n_top_words = 10\n",
    "\n",
    "tf_feature_name = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_name, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Aug/2019 15:50:49] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2019 15:51:10] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2019 15:51:10] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2019 15:51:10] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\"\"\"数据可视化，会弹出一个网页\"\"\"\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "data = pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)\n",
    "\n",
    "pyLDAvis.show(data)#可视化主题模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
